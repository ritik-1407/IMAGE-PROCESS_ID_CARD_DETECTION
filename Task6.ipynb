{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HHEwmBkm1KZh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/_p14qyt53xl7cpdfv7wby79r0000gn/T/ipykernel_91616/1233727652.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-02-14 20:17:52.816568: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6OaxNt13A1tu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A1uXcdy_A1OZ"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQT8-VjY1Ogr",
    "outputId": "fb028490-7240-4e83-ea8a-e43ec7055d0a"
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Install pytesseract using pip if not already installed\n",
    "# pip install pytesseract\n",
    "\n",
    "# Install Tesseract OCR engine: https://github.com/tesseract-ocr/tesseract\n",
    "# Make sure to add the Tesseract installation directory to your system PATH\n",
    "\n",
    "def extract_text_from_image(image):\n",
    "    # Open the image using PIL (Python Imaging Library)\n",
    "\n",
    "    # Perform OCR using pytesseract\n",
    "    text = pytesseract.image_to_string(image)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bsrp2LRc1QjZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "image_folder = '/Users/ritikgupta/Downloads/6_end_to_end/6_end_to_end/'\n",
    "# image_folder ='/content/drive/MyDrive/Colab Notebooks/1_classification/Test/Non_Ids/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Dy9mtw91FL0T"
   },
   "outputs": [],
   "source": [
    "def deskew_with_double_majority(original_image):\n",
    "    # Load the image\n",
    "    # original_image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "\n",
    "    gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply dilation and erosion\n",
    "    kernel = np.ones((25, 25), np.uint8)\n",
    "    dilation = cv2.dilate(gray, kernel, iterations=2)\n",
    "    erosion = cv2.erode(dilation, kernel, iterations=1)\n",
    "    new= erosion*gray\n",
    "\n",
    "\n",
    "    # Use Canny edge detection\n",
    "    edges = cv2.Canny(erosion, 50, 150, apertureSize=3)\n",
    "\n",
    "    # Apply Hough Line Transform\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)\n",
    "\n",
    "    if lines is None or len(lines) < 2:\n",
    "        raise ValueError(\"No lines detected for deskewing\")\n",
    "\n",
    "    # Extract angles from detected lines\n",
    "    angles = [line[0][1] for line in lines]\n",
    "\n",
    "    # First majority vote: Determine lines\n",
    "    line_votes = Counter(angles)\n",
    "    common_lines = line_votes.most_common(2)\n",
    "    majority_line = common_lines[0][0]\n",
    "\n",
    "    # Second majority vote: Vote on a common angle among the most important lines\n",
    "    important_lines = [line for line in lines if line[0][1] == majority_line]\n",
    "    important_angles = [line[0][1] for line in important_lines]\n",
    "\n",
    "    angle_votes = Counter(important_angles)\n",
    "    common_angles = angle_votes.most_common(2)\n",
    "    majority_angle = common_angles[0][0]\n",
    "\n",
    "    # Rotate the image to deskew it\n",
    "    (h, w) = original_image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    rotation_angle = np.degrees(majority_angle) - 90\n",
    "    M = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "    deskewed_image = cv2.warpAffine(original_image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    deskewed_image_gray = cv2.warpAffine(new, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "\n",
    "    return(deskewed_image,deskewed_image_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rT98hy5ig7KS"
   },
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZqUInL7agd4v"
   },
   "outputs": [],
   "source": [
    "def segmentation(original_image):\n",
    "    image_resized= tf.keras.preprocessing.image.img_to_array(original_image)/255.0\n",
    "    image_with_batch = np.expand_dims(image_resized, axis=0)\n",
    "    segmentation_mask = model1.predict(image_with_batch)\n",
    "    cut_out = image_resized  * segmentation_mask\n",
    "    cut_out=cut_out.reshape((512, 512, 3))\n",
    "    cut_out = (cut_out * 255).astype(np.uint8)\n",
    "    return cut_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aJg2286F3d1V"
   },
   "outputs": [],
   "source": [
    "def classify_image(image):\n",
    "    # Perform inference\n",
    "    prediction = model.predict(np.expand_dims(image, axis=0))\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3TIQf9doBIWy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_pipeline(original_image):\n",
    "    # Step 2: Classify the image\n",
    "    # cv2_imshow(original_image)\n",
    "    prediction = classify_image(original_image)\n",
    "\n",
    "    # Step 3: Post-process the prediction\n",
    "    if prediction <= 0.4:\n",
    "        print(prediction, \"ID card detected.\")\n",
    "        # # Step 4: Load the segmentation model and predict\n",
    "\n",
    "\n",
    "        cut_out = segmentation(original_image)\n",
    "        print(\"image============================================================\")\n",
    "#         cv2.imshow('2',cut_out)\n",
    "#         cv2.waitKey()\n",
    "\n",
    "        deskew_image,deskew_image_new = deskew_with_double_majority(cut_out)\n",
    "        print(\"deskew_image================================================== \")\n",
    "#         cv2.imshow('3',deskew_image)\n",
    "#         cv2.waitKey()\n",
    "\n",
    "        print(\"deskew_image morphological filters=============================\")\n",
    "#         cv2.imshow('4',deskew_image_new)\n",
    "#         cv2.waitKey()\n",
    "        image_with_batch = np.expand_dims(deskew_image, axis=0)\n",
    "\n",
    "        pred= model2.predict(image_with_batch)\n",
    "        pred = np.squeeze(pred)\n",
    "        pred = (pred*255).astype(np.uint8)\n",
    "#         cv2.imshow('4',deskew_image_new)\n",
    "#         cv2.waitKey()\n",
    "        text=extract_text_from_image(cut_out)\n",
    "        print(text,\"nkn\")\n",
    "\n",
    "    else:\n",
    "        print(prediction, \"Not an ID card.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wgCi6O7RjfHu"
   },
   "outputs": [],
   "source": [
    "model = load_model(r'/Users/ritikgupta/IPDA 23/All_trained_models/id_card_classifier2.h5',compile=False)\n",
    "model1 = load_model('/Users/ritikgupta/IPDA 23/All_trained_models/id_card_seg1.h5')\n",
    "model2 = load_model('/Users/ritikgupta/IPDA 23/All_trained_models/id_card_clean.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lADEIsOfC1_y",
    "outputId": "1ea52aca-1a6c-4647-f55d-078efd632ad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orignal image\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "[[0.01543304]] ID card detected.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd01ff70dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "image============================================================\n",
      "deskew_image================================================== \n",
      "deskew_image morphological filters=============================\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd01ff70940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      " nkn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        original_image = cv2.imread(image_path)\n",
    "        image = cv2.resize(original_image, (512, 512))\n",
    "        # original_image = original_image / 255.0\n",
    "        print(\"orignal image\")\n",
    "#         cv2.imshow('1',image)\n",
    "#         cv2.waitKey()\n",
    "\n",
    "        # print(image)\n",
    "        run_pipeline(image)\n",
    "     \n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGAwKBW5C8Ot"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
